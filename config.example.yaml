# QuantGPT configuration (copy to config.yaml and customize)
app:
  name: QuantGPT
  environment: development  # development | staging | production

openai:
  # Provider & model settings
  provider: openai
  # Use the exact model ID you intend to run (examples: gpt-4o, gpt-4o-mini, o3-mini, etc.)
  # Leave as-is and set the real model in your local config.yaml.
  model: "your-model-id-here"
  # Typical generation knobs
  temperature: 0.2
  max_output_tokens: 2048      # use 0 or null to let the server decide, if supported
  seed: null                   # set an int for reproducibility, if supported
  # Networking
  request_timeout_seconds: 30
  base_url: null               # set if youâ€™re proxying the OpenAI API (otherwise leave null)
  json_mode: false             # set true if you always expect JSON responses

logging:
  level: INFO                  # DEBUG | INFO | WARNING | ERROR
  file: logs/quantgpt.log
  json: false